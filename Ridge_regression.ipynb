{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAi2G9tY6us+gIzBCOxMSd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ABHAY7238/Road-to-Data-Scientist-/blob/main/Ridge_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ridge Regression\n",
        "Ridge regression is a model tuning method that is used to analyse any data that suffers from multicollinearity."
      ],
      "metadata": {
        "id": "RvNcixpHYE6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "from sklearn.linear_model import Ridge\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "3Cv6uiwwYJ_q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example data\n",
        "X = np.array([[1,1] , [1,2] , [2,2] , [2,3]])\n",
        "\n",
        "\n",
        "#target values\n",
        "y = np.dot(X,np.array([1,2]))+3\n",
        "\n",
        "\n",
        "#Ridge regression model\n",
        "ridge_reg = Ridge(alpha = 1.0)\n",
        "ridge_reg.fit(X,y)\n",
        "\n",
        "\n",
        "\n",
        "#print the coefficients\n",
        "print('Coefficients : ' , ridge_reg.coef_)\n",
        "\n",
        "\n",
        "#print intercepts\n",
        "print('Intercept : ' , ridge_reg.intercept_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ydj9aMGYKDY",
        "outputId": "302e9329-c755-4cd8-ee7d-ab96b712291e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients :  [0.8 1.4]\n",
            "Intercept :  4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COMAPRING SIMPLE LINEAR REGRESSION VS RIDGE REGRESION"
      ],
      "metadata": {
        "id": "xdvQFz5XYKGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORT THE LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression , Ridge\n",
        "from sklearn.metrics import mean_squared_error , mean_absolute_percentage_error , r2_score , mean_absolute_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "metadata": {
        "id": "A3i6BMDKYKJ6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset\n",
        "df = sns.load_dataset('titanic')"
      ],
      "metadata": {
        "id": "VreN0LqXYKNw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#selecting a subsets of columns for simplicity\n",
        "columns_to_use = ['survived' , 'pclass' , 'sex' , 'age' , 'fare']\n",
        "df = df[columns_to_use]\n",
        "\n",
        "#handling missing values\n",
        "df['age'].fillna(df['age'].mean() , inplace = True)\n",
        "\n",
        "#define feautres and target variables\n",
        "X = df.drop('survived' , axis = 1)\n",
        "y = df['survived']\n",
        "\n",
        "#split the data into training and testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.2 , random_state = 42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukZRTHq2YKQa",
        "outputId": "218d6193-fda0-4ccf-9186-e7d4d587919f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1111104682.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['age'].fillna(df['age'].mean() , inplace = True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define a pipeline for OneHotEncoding and model\n",
        "categorical_cols = ['sex']\n",
        "numerical_cols = ['age' , 'fare' , 'pclass']\n",
        "\n",
        "#preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers = [\n",
        "        ('num','passthrough',numerical_cols),\n",
        "        ('cat',OneHotEncoder(),categorical_cols)])\n",
        "\n",
        "\n",
        "#linear Regression Pipeline\n",
        "lr_pipeline = Pipeline([\n",
        "    ('preprocessor',preprocessor),\n",
        "    ('regressor',LinearRegression())])\n",
        "\n",
        "#ridge regression pipeline\n",
        "ridge_pipeline = Pipeline(steps =[('preprocessor',preprocessor),('regressor' , Ridge(alpha = 1.0))])"
      ],
      "metadata": {
        "id": "zwFuauYiYKTp"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train and evaluate  linear regression and ridge regression\n",
        "lr_pipeline.fit(X_train , y_train)\n",
        "lr_pred = lr_pipeline.predict(X_test)\n",
        "lr_mse = mean_squared_error(y_test , lr_pred)\n",
        "lr_r2 = r2_score(y_test , lr_pred)\n",
        "lr_mape = mean_absolute_percentage_error(y_test , lr_pred)\n",
        "lr_rmse = np.sqrt(lr_mse)\n",
        "\n",
        "#train and evaluate ridge regression\n",
        "ridge_pipeline.fit(X_train , y_train)\n",
        "ridge_pred = ridge_pipeline.predict(X_test)\n",
        "ridge_mse = mean_squared_error(y_test , ridge_pred)\n",
        "ridge_r2 = r2_score(y_test , ridge_pred)\n",
        "ridge_mape = mean_absolute_percentage_error(y_test , ridge_pred)\n",
        "ridge_rmse = np.sqrt(ridge_mse)\n",
        "\n",
        "#print the mean_Squared_errors of the both the linear_regression and ridge_regression\n",
        "print('Linear Regression MSE : ' , lr_mse)\n",
        "print('Ridge Regression MSE : ' , ridge_mse)\n",
        "print('linear regression r2_score : ' , lr_r2)\n",
        "print('ridge regression r2_score : ' , ridge_r2)\n",
        "print('linear regression mape : ' , lr_mape)\n",
        "print('ridge regression mape : ' , ridge_mape)\n",
        "print('linear regression rmse : ' , lr_rmse)\n",
        "print('ridge regression rmse : ' , ridge_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJZr10lvYKWr",
        "outputId": "76f42ece-ca59-4c2a-94af-22edf1d76e49"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression MSE :  0.13721032187197302\n",
            "Ridge Regression MSE :  0.13723013415703844\n",
            "linear regression r2_score :  0.4341884268854713\n",
            "ridge regression r2_score :  0.43410672734547373\n",
            "linear regression mape :  645237733491223.6\n",
            "ridge regression mape :  645980090467403.5\n",
            "linear regression rmse :  0.3704191165044982\n",
            "ridge regression rmse :  0.3704458586042479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## REGULARIZATION\n",
        "Regularization is a technique used in Machine Learning to prevent Overfittng of models on training data . Overfitting occurs when a model learns the training data too well and performs poorly on unseen data. In overfitting the data trained on testing data too well , including its noise and outliers , leading to poor generalization to unseen data. Regularization helps to solve this problem by adding penalty to the models complexity"
      ],
      "metadata": {
        "id": "kXU5jsIZYKZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RIDGE REGRESSION\n",
        "Ridge Regression is a type of linear Regression that includes a regulariazation term . The key idea behind Ridge Regression is to add a penalty term to\n",
        "regression is to find a new line that doesn't fit the training data as well as ordinary least squares regression , in order to achieve the better generalization to the new data .\n",
        "This is Particularly useful when dealing with multicollinearity , where the predictor variables are highly correlated or when the numbers of predictors exceeds the number of observations."
      ],
      "metadata": {
        "id": "7QMnb3wsYKcm"
      }
    }
  ]
}