{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNl5aJi5LRdN8WvPySnym3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ABHAY7238/Road-to-Data-Scientist-/blob/main/Naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6d0ddb5"
      },
      "source": [
        "### Bayes' Theorem\n",
        "\n",
        "**Definition:** Bayes' Theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the event. It is a fundamental concept in probability theory and statistics, used to update the probability estimate for a hypothesis as more evidence or information becomes available. It's often stated as 'the probability of A given B equals the probability of B given A, times the probability of A, divided by the probability of B'.\n",
        "\n",
        "**Formula:**\n",
        "\n",
        "```\n",
        "P(A|B) = [P(B|A) * P(A)] / P(B)\n",
        "```\n",
        "\n",
        "Where:\n",
        "*   `P(A|B)` is the posterior probability: the probability of event A occurring given that event B has occurred.\n",
        "*   `P(B|A)` is the likelihood: the probability of event B occurring given that event A has occurred.\n",
        "*   `P(A)` is the prior probability of A: the initial probability of event A occurring before any new evidence is considered.\n",
        "*   `P(B)` is the marginal probability of B: the probability of event B occurring.\n",
        "\n",
        "### Naive Bayes Algorithm\n",
        "\n",
        "**Definition:** The Naive Bayes algorithm is a classification technique based on Bayes' Theorem, but with a strong (and 'naive') assumption of independence among predictors. This means it assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. Despite this simplifying assumption, Naive Bayes classifiers have proven to be quite effective in many real-world scenarios, especially in text classification and spam detection.\n",
        "\n",
        "**Formula (for a classifier):**\n",
        "\n",
        "For a given class `Ck` and a dependent feature vector `x = (x1, x2, ..., xn)`, the Naive Bayes classifier predicts the class `Ck` such that:\n",
        "\n",
        "```\n",
        "P(Ck | x1, ..., xn) = P(Ck) * P(x1 | Ck) * P(x2 | Ck) * ... * P(xn | Ck) / P(x1, ..., xn)\n",
        "```\n",
        "\n",
        "Since `P(x1, ..., xn)` is constant for all classes, we can simplify the decision rule to:\n",
        "\n",
        "```\n",
        "Class = argmax[Ck] P(Ck) * P(x1 | Ck) * P(x2 | Ck) * ... * P(xn | Ck)\n",
        "```\n",
        "\n",
        "Where:\n",
        "*   `P(Ck | x1, ..., xn)` is the posterior probability of class `Ck` given the predictors `x1` to `xn`.\n",
        "*   `P(Ck)` is the prior probability of class `Ck`.\n",
        "*   `P(xi | Ck)` is the likelihood of predictor `xi` given class `Ck`.\n",
        "*   `P(x1, ..., xn)` is the marginal probability of the predictors (often ignored in classification as it's a normalizing constant).\n",
        "*   `argmax[Ck]` means we select the class `Ck` that maximizes the posterior probability."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#now import naive bayes libraries\n",
        "from sklearn.naive_bayes import GaussianNB , MultinomialNB , BernoulliNB\n",
        "#now import train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score , confusion_matrix , classification_report\n",
        "from sklearn.datasets import load_iris"
      ],
      "metadata": {
        "id": "V_pEFl6oRsNW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load the datasets\n",
        "iris = load_iris()\n",
        "#now divide the dataset into x and y\n",
        "x = iris.data\n",
        "y = iris.target\n",
        "#now train_test_split the data\n",
        "x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.25 , random_state = 42)"
      ],
      "metadata": {
        "id": "Xo1uUJTpRsRI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#intialize the model\n",
        "model = GaussianNB()\n",
        "#fit the model\n",
        "model.fit(x_train , y_train)\n",
        "#predict the test data\n",
        "y_pred = model.predict(x_test)\n",
        "#evaluate the model\n",
        "print('accuracy_score : ',accuracy_score(y_test , y_pred))\n",
        "print('confusion_matrix : \\n',confusion_matrix(y_test , y_pred))\n",
        "print('classification_report : \\n',classification_report(y_test , y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DV1miYaRsUQ",
        "outputId": "f9bd6da1-2748-4ed2-accc-845ef2fad887"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score :  1.0\n",
            "confusion_matrix : \n",
            " [[15  0  0]\n",
            " [ 0 11  0]\n",
            " [ 0  0 12]]\n",
            "classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       1.00      1.00      1.00        11\n",
            "           2       1.00      1.00      1.00        12\n",
            "\n",
            "    accuracy                           1.00        38\n",
            "   macro avg       1.00      1.00      1.00        38\n",
            "weighted avg       1.00      1.00      1.00        38\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOW USING THE MULTINOMIAL MODEL"
      ],
      "metadata": {
        "id": "tRcgTDQvRsXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model  = MultinomialNB()\n",
        "model.fit(x_train , y_train)\n",
        "\n",
        "#predict the model\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "#evaluate the model\n",
        "print('accuracy_score : ',accuracy_score(y_test , y_pred))\n",
        "print('confusion_matrix : \\n',confusion_matrix(y_test , y_pred))\n",
        "print('classification_report : \\n',classification_report(y_test , y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o1dJlvYRsaX",
        "outputId": "750873a5-cb65-4290-c888-76145d0996d4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score :  0.9736842105263158\n",
            "confusion_matrix : \n",
            " [[15  0  0]\n",
            " [ 0 11  0]\n",
            " [ 0  1 11]]\n",
            "classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        15\n",
            "           1       0.92      1.00      0.96        11\n",
            "           2       1.00      0.92      0.96        12\n",
            "\n",
            "    accuracy                           0.97        38\n",
            "   macro avg       0.97      0.97      0.97        38\n",
            "weighted avg       0.98      0.97      0.97        38\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NOW USING THE BERNOULIS MODEL"
      ],
      "metadata": {
        "id": "kt3KsFfPRsdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BernoulliNB()\n",
        "model.fit(x_train , y_train)\n",
        "\n",
        "#predict the model\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "#evaluate the model\n",
        "print('accuracy_score : ',accuracy_score(y_test , y_pred))\n",
        "print('confusion_matrix : \\n',confusion_matrix(y_test , y_pred))\n",
        "print('classification_report : \\n',classification_report(y_test , y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLmSdLRnRsgN",
        "outputId": "da2a85a9-e810-4acc-9b62-9cf5d9bec5a0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy_score :  0.2894736842105263\n",
            "confusion_matrix : \n",
            " [[ 0 15  0]\n",
            " [ 0 11  0]\n",
            " [ 0 12  0]]\n",
            "classification_report : \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        15\n",
            "           1       0.29      1.00      0.45        11\n",
            "           2       0.00      0.00      0.00        12\n",
            "\n",
            "    accuracy                           0.29        38\n",
            "   macro avg       0.10      0.33      0.15        38\n",
            "weighted avg       0.08      0.29      0.13        38\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "54zo3nzrRsio"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}